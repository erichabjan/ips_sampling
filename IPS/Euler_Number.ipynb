{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ce414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from cymetric.models.helper import prepare_basis as prepare_tf_basis\n",
    "\n",
    "import sys\n",
    "rep_path = os.getcwd().replace('/IPS', '')\n",
    "sys.path.append(rep_path)\n",
    "import python_functions as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309cb5d5",
   "metadata": {},
   "source": [
    "### IPS outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5017ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cicy_name = 'multi_eq' #'multi_eq' 'quintic' 'bicubic'\n",
    "number_regions = 1\n",
    "base_path = f'/Users/erich/Downloads/Northeastern/ips_home/Data/ips_output/{cicy_name}/'\n",
    "\n",
    "points_real = pd.read_csv(base_path + f\"points_real_{number_regions}.csv\", header=None).values\n",
    "points_imag = pd.read_csv(base_path + f\"points_imag_{number_regions}.csv\", header=None).values\n",
    "\n",
    "weights = pd.read_csv(base_path + f\"weights_{number_regions}.csv\", header=None).values.flatten()\n",
    "omegas = pd.read_csv(base_path + f\"omegas_{number_regions}.csv\", header=None).values.flatten()\n",
    "kappas = pd.read_csv(base_path + f\"kappas_{number_regions}.csv\", header=None).values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ce3cb",
   "metadata": {},
   "source": [
    "### Import BASIS file from `cymetric` and prepare points+weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd1394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = f'/Users/erich/Downloads/Northeastern/ips_home/Data/{cicy_name}'\n",
    "\n",
    "#riemann_path = os.path.join(dirname, 'riemann.pickle')\n",
    "\n",
    "BASIS = np.load(os.path.join(dirname, 'basis.pickle'), allow_pickle=True)\n",
    "BASIS = prepare_tf_basis(BASIS)\n",
    "new_basis = {}\n",
    "for key in BASIS:\n",
    "    new_basis[key] = tf.cast(BASIS[key], dtype=tf.complex64)\n",
    "BASIS = new_basis\n",
    "\n",
    "#pts_s = points_real + 1j * points_imag\n",
    "pts_s = np.concatenate([points_real, points_imag], axis=1).astype(np.float32)\n",
    "#wo_s = weights\n",
    "wo_s = np.concatenate([weights[:, None], omegas[:, None]], axis=1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae639e89",
   "metadata": {},
   "source": [
    "### Monomials and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cicy_name == 'multi_eq':\n",
    "\n",
    "    monomials_eq1 = np.array([\n",
    "        [3, 0, 0, 0,  0, 0, 0, 0],\n",
    "        [2, 1, 0, 0,  0, 0, 0, 0],\n",
    "        [0, 1, 1, 1,  0, 0, 0, 0],\n",
    "        [0, 0, 3, 0,  0, 0, 0, 0],\n",
    "    ], dtype=np.int64)\n",
    "\n",
    "    monomials_eq2 = np.array([\n",
    "        [0, 0, 0, 0,  3, 0, 0, 0],\n",
    "        [0, 0, 0, 0,  2, 1, 0, 0],\n",
    "        [0, 0, 0, 0,  0, 1, 1, 1],\n",
    "        [0, 0, 0, 0,  0, 0, 0, 3],\n",
    "    ], dtype=np.int64)\n",
    "\n",
    "    monomials_eq3 = np.array([\n",
    "        [1, 0, 0, 0,  1, 0, 0, 0],\n",
    "        [0, 1, 0, 0,  0, 1, 0, 0],\n",
    "        [0, 0, 1, 0,  0, 0, 1, 0],\n",
    "        [0, 0, 0, 1,  0, 0, 0, 1],\n",
    "    ], dtype=np.int64)\n",
    "\n",
    "    monomials = [monomials_eq1, monomials_eq2, monomials_eq3]\n",
    "\n",
    "if cicy_name == 'bicubic':\n",
    "\n",
    "    monomials_eq1 = np.array([\n",
    "        [3, 0, 0, 0, 3, 0],\n",
    "        [0, 3, 0, 3, 0, 0],\n",
    "        [2, 1, 0, 1, 2, 0],\n",
    "        [1, 2, 0, 2, 1, 0],\n",
    "        [1, 0, 2, 0, 1, 2],\n",
    "        [0, 1, 2, 1, 0, 2],\n",
    "    ], dtype=np.int64)\n",
    "\n",
    "    monomials = [monomials_eq1]\n",
    "\n",
    "\n",
    "if cicy_name == 'quintic':\n",
    "\n",
    "    monomials = [np.array([\n",
    "        [5,0,0,0,0],   \n",
    "        [0,5,0,0,0],   \n",
    "        [0,0,5,0,0], \n",
    "        [0,0,0,5,0], \n",
    "        [0,0,0,0,5],\n",
    "        [1,1,1,1,1],\n",
    "    ], dtype=np.int64)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5e4cb",
   "metadata": {},
   "source": [
    "# Compute Euler Characteristic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e15fb7",
   "metadata": {},
   "source": [
    "### Build the metric model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae261427",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_model = pf.SpectralFSModelComp(None, BASIS = BASIS, alpha=[1.]*5, deg=2, monomials=monomials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12e7a24",
   "metadata": {},
   "source": [
    "### Compute curvature (Riemann tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a7fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cymetric_path = f'/Users/erich/Downloads/Northeastern/ips_home/Data/{cicy_name}/riemann_mypts_{cicy_name}.pickle'\n",
    "\n",
    "riemann_tensor = pf.compute_riemann(base_path + f\"riemann_mypts_{cicy_name}_new.pickle\", pts_s, comp_model, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bfa2e1",
   "metadata": {},
   "source": [
    "### Chern classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2, c3, c3_form = pf.get_chern_classes(riemann_tensor, comp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cac65e8",
   "metadata": {},
   "source": [
    "### Naive $\\chi$ from your samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_naive = tf.math.real(pf.integrate_native(c3_form, pts_s, wo_s, comp_model, normalize_to_vol=5.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e4748",
   "metadata": {},
   "source": [
    "### $\\chi$ for IPS wieghted by $\\kappa$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_variances = pf.analyze_regions(c3_form, pts_s, wo_s, comp_model, kappas, verbose=False)\n",
    "\n",
    "chi_weighted = tf.math.real(pf.integrate_variance_kappa_weighted(c3_form, pts_s, wo_s, comp_model, variances=regional_variances, kappas=kappas, normalize_to_vol=5.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49d92da",
   "metadata": {},
   "source": [
    "### Compare with true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07218b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cicy_name == 'multi_eq':\n",
    "    chi_true = pf.euler_cicy([3, 3], [[3, 0], [0, 3], [1, 1]], check_cy=True)\n",
    "\n",
    "if cicy_name == 'bicubic':\n",
    "    chi_true = pf.euler_cicy([2, 2], [[3, 3]], check_cy=True)\n",
    "    \n",
    "if cicy_name == 'quintic':\n",
    "    chi_true = pf.euler_cicy([4], [[5]], check_cy=True)\n",
    "\n",
    "\n",
    "per_err = abs((chi_weighted.numpy() - chi_true) / chi_true) * 100\n",
    "\n",
    "print(f'The true Euler number is: {chi_true}')\n",
    "print(f'The Euler number from sampling is: {chi_weighted.numpy()}')\n",
    "print(f'The percent error is: {per_err}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPSenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
